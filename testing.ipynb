{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b211bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetV2S\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_hybrid_resnet_efficientnet_model(input_shape=(224, 224, 3)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # --- ResNet50 branch ---\n",
    "    resnet_base = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    resnet_base.trainable = False\n",
    "    x1 = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "    x1 = resnet_base(x1, training=False)\n",
    "    x1 = GlobalAveragePooling2D()(x1)\n",
    "\n",
    "    # --- EfficientNetV2S branch ---\n",
    "    efficientnet_base = EfficientNetV2S(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    efficientnet_base.trainable = False\n",
    "    x2 = tf.keras.applications.efficientnet_v2.preprocess_input(inputs)\n",
    "    x2 = efficientnet_base(x2, training=False)\n",
    "    x2 = GlobalAveragePooling2D()(x2)\n",
    "\n",
    "\n",
    "    x = Concatenate()([x1, x2])  # Hybrid feature vector\n",
    "\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f89c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_hybrid_resnet_efficientnet_model(input_shape=(224, 224, 3))\n",
    "model.load_weights('hybrid_gender_weights.weights.h5')\n",
    "print(\"✅ Weights loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_entire_dataset(model, val_dir, image_size=(224, 224)):\n",
    "    total_images = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    total_male = 0\n",
    "    total_female = 0\n",
    "    correct_male = 0\n",
    "    correct_female = 0\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for label in ['male', 'female']:\n",
    "        class_dir = os.path.join(val_dir, label)\n",
    "        for fname in os.listdir(class_dir):\n",
    "            if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img_path = os.path.join(class_dir, fname)\n",
    "                img = image.load_img(img_path, target_size=image_size)\n",
    "                img_array = image.img_to_array(img)\n",
    "                img_array = tf.expand_dims(img_array, axis=0)\n",
    "                img_array = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
    "\n",
    "                pred_prob = model.predict(img_array, verbose=0)[0][0]\n",
    "                pred_label = 'male' if pred_prob > 0.5 else 'female'\n",
    "\n",
    "                true_label = label\n",
    "                y_true.append(1 if true_label == 'male' else 0)\n",
    "                y_pred.append(1 if pred_label == 'male' else 0)\n",
    "\n",
    "                total_images += 1\n",
    "                if true_label == 'male':\n",
    "                    total_male += 1\n",
    "                    if pred_label == 'male':\n",
    "                        correct_male += 1\n",
    "                        total_correct += 1\n",
    "                else:\n",
    "                    total_female += 1\n",
    "                    if pred_label == 'female':\n",
    "                        correct_female += 1\n",
    "                        total_correct += 1\n",
    "\n",
    "    overall_acc = (total_correct / total_images) * 100\n",
    "\n",
    "    print(\"\\n✅ Evaluation Summary:\")\n",
    "    print(f\"✅ Overall Accuracy           : {overall_acc:.2f}%\\n\")\n",
    "\n",
    "    print(f\" Male Images     → Total: {total_male}, Correct: {correct_male}, Incorrect: {total_male - correct_male}\")\n",
    "    print(f\" Female Images   → Total: {total_female}, Correct: {correct_female}, Incorrect: {total_female - correct_female}\")\n",
    "\n",
    "    # Compute metrics first!\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Female', 'Male']))\n",
    "    print(f\"F1 Score     : {f1:.4f}\")\n",
    "    print(f\"Precision    : {precision:.4f}\")\n",
    "    print(f\"Recall       : {recall:.4f}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Female', 'Male'], yticklabels=['Female', 'Male'])\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d16e99f",
   "metadata": {},
   "source": [
    "##Change the val_path with your actual datapath where the images are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341c793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with your local validation directory\n",
    "val_path = val_path = r\"path\\to\\your\\validation\\dataset\"\n",
    "\n",
    "\n",
    "evaluate_entire_dataset(model, val_path, image_size=(224, 224))\n",
    "# The code above evaluates the model on the validation dataset and prints the classification report, confusion matrix, and other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914d5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
